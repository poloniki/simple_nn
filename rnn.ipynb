{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[-0.00276458]]\n",
      "True: [12]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "data = np.array([10, 15, 8])\n",
    "target = np.array([12])\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 1  # input node count\n",
    "hidden_size = 16  # hidden node count\n",
    "output_size = 1  # output node count\n",
    "timesteps = 3  # timesteps for RNN\n",
    "learning_rate = 0.01  # learning rate\n",
    "\n",
    "# Initialize weights\n",
    "Wxh = np.random.randn(hidden_size, input_size) * 0.01  # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # hidden to hidden\n",
    "Why = np.random.randn(output_size, hidden_size) * 0.01  # hidden to output\n",
    "\n",
    "# Initialize biases\n",
    "bh = np.zeros((hidden_size, 1))  # hidden bias\n",
    "by = np.zeros((output_size, 1))  # output bias\n",
    "\n",
    "def forward(x, h_prev):\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h_prev) + bh)\n",
    "    y = np.dot(Why, h) + by\n",
    "    return y, h\n",
    "\n",
    "def backward(target, dy, h, h_prev, x):\n",
    "    dWhy = np.dot(dy, h.T)\n",
    "    dby = dy\n",
    "    dh = np.dot(Why.T, dy)\n",
    "    dhraw = (1 - h * h) * dh  # backprop through tanh\n",
    "    dbh = dhraw\n",
    "    dWhh = np.dot(dhraw, h_prev.T)\n",
    "    dWxh = np.dot(dhraw, x.T)\n",
    "    return dWxh, dWhh, dbh, dby, dWhy\n",
    "\n",
    "def update_model(dWxh, dWhh, dbh, dby, dWhy):\n",
    "    global Wxh, Whh, bh, by, Why\n",
    "    Wxh -= learning_rate * dWxh\n",
    "    Whh -= learning_rate * dWhh\n",
    "    bh -= learning_rate * dbh\n",
    "    by -= learning_rate * dby\n",
    "    Why -= learning_rate * dWhy\n",
    "\n",
    "h = np.zeros((hidden_size, 1))  # reset RNN memory\n",
    "# forward pass\n",
    "for i in range(timesteps):\n",
    "    x = data[i].reshape(-1, 1)\n",
    "    y, h = forward(x, h)\n",
    "\n",
    "# compute loss\n",
    "loss = np.square(y - target).sum()\n",
    "\n",
    "# backward pass\n",
    "dy = 2.0 * (y - target)\n",
    "dWxh, dWhh, dbh, dby, dWhy = backward(target.reshape(-1, 1), dy, h, h, x)\n",
    "\n",
    "# update model\n",
    "update_model(dWxh, dWhh, dbh, dby, dWhy)\n",
    "\n",
    "print(\"Predicted:\", y)\n",
    "print(\"True:\", target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_7/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.28243372]], dtype=float32)>,\n",
       " <tf.Variable 'dense_7/bias:0' shape=(1,) dtype=float32, numpy=array([0.44750458], dtype=float32)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
