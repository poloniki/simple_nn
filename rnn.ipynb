{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[-0.00276458]]\n",
      "True: [12]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "data = np.array([10, 15, 8])\n",
    "target = np.array([12])\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 1  # input node count\n",
    "hidden_size = 16  # hidden node count\n",
    "output_size = 1  # output node count\n",
    "timesteps = 3  # timesteps for RNN\n",
    "learning_rate = 0.01  # learning rate\n",
    "\n",
    "# Initialize weights\n",
    "Wxh = np.random.randn(hidden_size, input_size) * 0.01  # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # hidden to hidden\n",
    "Why = np.random.randn(output_size, hidden_size) * 0.01  # hidden to output\n",
    "\n",
    "# Initialize biases\n",
    "bh = np.zeros((hidden_size, 1))  # hidden bias\n",
    "by = np.zeros((output_size, 1))  # output bias\n",
    "\n",
    "def forward(x, h_prev):\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h_prev) + bh)\n",
    "    y = np.dot(Why, h) + by\n",
    "    return y, h\n",
    "\n",
    "def backward(target, dy, h, h_prev, x):\n",
    "    dWhy = np.dot(dy, h.T)\n",
    "    dby = dy\n",
    "    dh = np.dot(Why.T, dy)\n",
    "    dhraw = (1 - h * h) * dh  # backprop through tanh\n",
    "    dbh = dhraw\n",
    "    dWhh = np.dot(dhraw, h_prev.T)\n",
    "    dWxh = np.dot(dhraw, x.T)\n",
    "    return dWxh, dWhh, dbh, dby, dWhy\n",
    "\n",
    "def update_model(dWxh, dWhh, dbh, dby, dWhy):\n",
    "    global Wxh, Whh, bh, by, Why\n",
    "    Wxh -= learning_rate * dWxh\n",
    "    Whh -= learning_rate * dWhh\n",
    "    bh -= learning_rate * dbh\n",
    "    by -= learning_rate * dby\n",
    "    Why -= learning_rate * dWhy\n",
    "\n",
    "h = np.zeros((hidden_size, 1))  # reset RNN memory\n",
    "# forward pass\n",
    "for i in range(timesteps):\n",
    "    x = data[i].reshape(-1, 1)\n",
    "    y, h = forward(x, h)\n",
    "\n",
    "# compute loss\n",
    "loss = np.square(y - target).sum()\n",
    "\n",
    "# backward pass\n",
    "dy = 2.0 * (y - target)\n",
    "dWxh, dWhh, dbh, dby, dWhy = backward(target.reshape(-1, 1), dy, h, h, x)\n",
    "\n",
    "# update model\n",
    "update_model(dWxh, dWhh, dbh, dby, dWhy)\n",
    "\n",
    "print(\"Predicted:\", y)\n",
    "print(\"True:\", target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.array([1.87])\n",
    "y_train = np.array([0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.9445\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0423\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4163\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9591\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6123\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3415\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1252\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9493\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8043\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6835\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5820\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4961\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4232\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3610\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3079\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2624\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2234\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1901\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1615\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1371\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1162\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0984\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.0831\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0702\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0592\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0498\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0419\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0352\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0296\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0248\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0121\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0101\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0084\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0070\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0059\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0041\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0023\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 955us/step - loss: 0.0016\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1931e-04\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6250e-04\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3229e-04\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2421e-04\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3452e-04\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 954us/step - loss: 3.6011e-04\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 940us/step - loss: 2.9840e-04\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4723e-04\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0481e-04\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6965e-04\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4050e-04\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 946us/step - loss: 1.1636e-04\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 933us/step - loss: 9.6349e-05\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 912us/step - loss: 7.9777e-05\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6051e-05\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4682e-05\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5267e-05\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7471e-05\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1016e-05\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5671e-05\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.1248e-05\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7585e-05\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4553e-05\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2043e-05\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9664e-06\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 935us/step - loss: 8.2480e-06\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 905us/step - loss: 6.8250e-06\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 905us/step - loss: 5.6477e-06\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6734e-06\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8668e-06\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1998e-06\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6476e-06\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1905e-06\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8127e-06\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4997e-06\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2408e-06\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0266e-06\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4936e-07\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0281e-07\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8144e-07\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8111e-07\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 965us/step - loss: 3.9805e-07\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2926e-07\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7244e-07\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2539e-07\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8648e-07\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 972us/step - loss: 1.5424e-07\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 867us/step - loss: 1.2760e-07\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0556e-07\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7297e-08\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2231e-08\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9750e-08\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9455e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d036ec80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='relu', input_dim=1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_6/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.98019725]], dtype=float32)>,\n",
       " <tf.Variable 'dense_6/bias:0' shape=(1,) dtype=float32, numpy=array([-0.05452294], dtype=float32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
